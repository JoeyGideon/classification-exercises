{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = acquire.get_titanic_data()\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (498, 10), (498,)\n",
      "Validation set shape: (214, 10), (214,)\n",
      "Testing set shape: (179, 10), (179,)\n"
     ]
    }
   ],
   "source": [
    "df_titanic = prepare.prep_titanic(df_titanic)\n",
    "df_titanic.head()\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data(df_titanic, 'survived')\n",
    "\n",
    "# print the shapes of the resulting datasets\n",
    "print(f'Training set shape: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Validation set shape: {X_validate.shape}, {y_validate.shape}')\n",
    "print(f'Testing set shape: {X_test.shape}, {y_test.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (knn): 0.7469879518072289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create the classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the training data\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "# compute the accuracy score\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# print the accuracy score\n",
    "print(f'Training accuracy (knn): {accuracy}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6312849162011173\n",
      "Confusion matrix:\n",
      "[[83 27]\n",
      " [39 30]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.72       110\n",
      "           1       0.53      0.43      0.48        69\n",
      "\n",
      "    accuracy                           0.63       179\n",
      "   macro avg       0.60      0.59      0.60       179\n",
      "weighted avg       0.62      0.63      0.62       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# compute the accuracy score on the test data\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# compute the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "\n",
    "# print the results\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "print(f'Confusion matrix:\\n{cm}')\n",
    "print(f'Classification report:\\n{cr}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "True Positive Rate (Recall): 0.43\n",
      "False Positive Rate: 0.25\n",
      "True Negative Rate: 0.75\n",
      "False Negative Rate: 0.57\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.72       110\n",
      "           1       0.53      0.43      0.48        69\n",
      "\n",
      "    accuracy                           0.63       179\n",
      "   macro avg       0.60      0.59      0.60       179\n",
      "weighted avg       0.62      0.63      0.62       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# compute and print the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# extract the true positive, false positive, true negative, and false negative rates from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "tnr = tn / (tn + fp)\n",
    "fnr = fn / (fn + tp)\n",
    "\n",
    "# print the true positive rate, false positive rate, true negative rate, and false negative rate\n",
    "print(f'True Positive Rate (Recall): {tpr:.2f}')\n",
    "print(f'False Positive Rate: {fpr:.2f}')\n",
    "print(f'True Negative Rate: {tnr:.2f}')\n",
    "print(f'False Negative Rate: {fnr:.2f}')\n",
    "\n",
    "# compute and print the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(f'Classification Report:\\n{cr}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run through steps 1-3 setting k to 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (knn): 0.6947791164658634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create the classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the training data\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "# compute the accuracy score\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# print the accuracy score\n",
    "print(f'Training accuracy (knn): {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6927374301675978\n",
      "Confusion matrix:\n",
      "[[101   9]\n",
      " [ 46  23]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79       110\n",
      "           1       0.72      0.33      0.46        69\n",
      "\n",
      "    accuracy                           0.69       179\n",
      "   macro avg       0.70      0.63      0.62       179\n",
      "weighted avg       0.70      0.69      0.66       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy score on the test data\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred1 = knn.predict(X_test)\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# compute the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "\n",
    "# print the results\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "print(f'Confusion matrix:\\n{cm}')\n",
    "print(f'Classification report:\\n{cr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "True Positive Rate (Recall): 0.33\n",
      "False Positive Rate: 0.08\n",
      "True Negative Rate: 0.92\n",
      "False Negative Rate: 0.67\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79       110\n",
      "           1       0.72      0.33      0.46        69\n",
      "\n",
      "    accuracy                           0.69       179\n",
      "   macro avg       0.70      0.63      0.62       179\n",
      "weighted avg       0.70      0.69      0.66       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred1 = knn.predict(X_test)\n",
    "\n",
    "# compute and print the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "\n",
    "# extract the true positive, false positive, true negative, and false negative rates from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "tnr = tn / (tn + fp)\n",
    "fnr = fn / (fn + tp)\n",
    "\n",
    "# print the true positive rate, false positive rate, true negative rate, and false negative rate\n",
    "print(f'True Positive Rate (Recall): {tpr:.2f}')\n",
    "print(f'False Positive Rate: {fpr:.2f}')\n",
    "print(f'True Negative Rate: {tnr:.2f}')\n",
    "print(f'False Negative Rate: {fnr:.2f}')\n",
    "\n",
    "# compute and print the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(f'Classification Report:\\n{cr}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run through steps 1-3 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (knn): 0.6746987951807228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create the classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "# fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the training data\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "# compute the accuracy score\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# print the accuracy score\n",
    "print(f'Training accuracy (knn): {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6927374301675978\n",
      "Confusion matrix:\n",
      "[[101   9]\n",
      " [ 46  23]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79       110\n",
      "           1       0.72      0.33      0.46        69\n",
      "\n",
      "    accuracy                           0.69       179\n",
      "   macro avg       0.70      0.63      0.62       179\n",
      "weighted avg       0.70      0.69      0.66       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy score on the test data\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred2 = knn.predict(X_test)\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred2)\n",
    "\n",
    "# compute the classification report\n",
    "cr = classification_report(y_test, y_pred2)\n",
    "\n",
    "# print the results\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "print(f'Confusion matrix:\\n{cm}')\n",
    "print(f'Classification report:\\n{cr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "True Positive Rate (Recall): 0.33\n",
      "False Positive Rate: 0.08\n",
      "True Negative Rate: 0.92\n",
      "False Negative Rate: 0.67\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79       110\n",
      "           1       0.72      0.33      0.46        69\n",
      "\n",
      "    accuracy                           0.69       179\n",
      "   macro avg       0.70      0.63      0.62       179\n",
      "weighted avg       0.70      0.69      0.66       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred2 = knn.predict(X_test)\n",
    "\n",
    "# compute and print the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred2)\n",
    "\n",
    "# extract the true positive, false positive, true negative, and false negative rates from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "tnr = tn / (tn + fp)\n",
    "fnr = fn / (fn + tp)\n",
    "\n",
    "# print the true positive rate, false positive rate, true negative rate, and false negative rate\n",
    "print(f'True Positive Rate (Recall): {tpr:.2f}')\n",
    "print(f'False Positive Rate: {fpr:.2f}')\n",
    "print(f'True Negative Rate: {tnr:.2f}')\n",
    "print(f'False Negative Rate: {fnr:.2f}')\n",
    "\n",
    "# compute and print the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(f'Classification Report:\\n{cr}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "The two models have different evaluation metrics. The first model with k=10 has a higher training accuracy of 0.6948 and a lower test accuracy of 0.6648. The second model with k=20 has a lower training accuracy of 0.6747 and a higher test accuracy of 0.6927. \n",
    "\n",
    "In terms of the classification report, the second model with k=20 has a higher precision, recall, and f1-score for the positive class (1) indicating that it is better at predicting the survival of passengers who did not survive in the Titanic disaster. However, the first model with k=10 has a higher precision, recall, and f1-score for the negative class (0) indicating that it is better at predicting the survival of passengers who survived.\n",
    "\n",
    "Overall, the second model with k=20 performs slightly better on the in-sample data as it has a higher test accuracy and better performance on the positive class. However, it's important to keep in mind that the performance of the models can vary depending on the specific data being used and other factors such as the choice of distance metric.\n",
    "\n",
    "I would use the k=5 because it has the highest accuracy score.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k set at 10\n",
      "\n",
      "Validation accuracy: 0.616822429906542\n",
      "Confusion matrix:\n",
      " [[114  18]\n",
      " [ 64  18]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.86      0.74       132\n",
      "           1       0.50      0.22      0.31        82\n",
      "\n",
      "    accuracy                           0.62       214\n",
      "   macro avg       0.57      0.54      0.52       214\n",
      "weighted avg       0.59      0.62      0.57       214\n",
      "\n",
      "\n",
      "k set at 20\n",
      "\n",
      "Validation accuracy: 0.6588785046728972\n",
      "Confusion matrix:\n",
      " [[123   9]\n",
      " [ 64  18]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.93      0.77       132\n",
      "           1       0.67      0.22      0.33        82\n",
      "\n",
      "    accuracy                           0.66       214\n",
      "   macro avg       0.66      0.58      0.55       214\n",
      "weighted avg       0.66      0.66      0.60       214\n",
      "\n",
      "Model with k=20 performs best on out-of-sample data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate the first model with k=10\n",
    "knn1 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn1.fit(X_train, y_train)\n",
    "y_pred1 = knn1.predict(X_validate)\n",
    "\n",
    "print(\"k set at 10\\n\")\n",
    "print(\"Validation accuracy:\", accuracy_score(y_validate, y_pred1))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_validate, y_pred1))\n",
    "print(\"Classification report:\\n\", classification_report(y_validate, y_pred1))\n",
    "\n",
    "# Train and evaluate the second model with k=20\n",
    "knn2 = KNeighborsClassifier(n_neighbors=20)\n",
    "knn2.fit(X_train, y_train)\n",
    "y_pred2 = knn2.predict(X_validate)\n",
    "\n",
    "print(\"\\nk set at 20\\n\")\n",
    "print(\"Validation accuracy:\", accuracy_score(y_validate, y_pred2))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_validate, y_pred2))\n",
    "print(\"Classification report:\\n\", classification_report(y_validate, y_pred2))\n",
    "\n",
    "# Determine which model performs best on out-of-sample data\n",
    "if accuracy_score(y_validate, y_pred1) > accuracy_score(y_validate, y_pred2):\n",
    "    print(\"Model with k=10 performs best on out-of-sample data\")\n",
    "else:\n",
    "    print(\"Model with k=20 performs best on out-of-sample data\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
