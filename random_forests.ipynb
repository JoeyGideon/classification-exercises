{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new notebook, random_forests, and work with titanic data to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = acquire.get_titanic_data()\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass  sex   age  sibsp  parch     fare  alone  \\\n",
       "0             0         0       3    1  22.0      1      0   7.2500      0   \n",
       "1             1         1       1    0  38.0      1      0  71.2833      0   \n",
       "2             2         1       3    0  26.0      0      0   7.9250      1   \n",
       "3             3         1       1    0  35.0      1      0  53.1000      0   \n",
       "4             4         0       3    1  35.0      0      0   8.0500      1   \n",
       "\n",
       "   embarked_Q  embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = prepare.prep_titanic(df_titanic)\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (498, 10), (498,)\n",
      "Validation set shape: (214, 10), (214,)\n",
      "Testing set shape: (179, 10), (179,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data(df_titanic, 'survived')\n",
    "\n",
    "# print the shapes of the resulting datasets\n",
    "print(f'Training set shape: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Validation set shape: {X_validate.shape}, {y_validate.shape}')\n",
    "print(f'Testing set shape: {X_test.shape}, {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9759036144578314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the classifier\n",
    "rf = RandomForestClassifier(random_state=123, min_samples_leaf=1, max_depth=10)\n",
    "\n",
    "# fit the classifier to the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the training data\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "# compute the accuracy score\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# print the accuracy score\n",
    "print(f'Training accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9759036144578314\n",
      "Confusion matrix:\n",
      "[[307   0]\n",
      " [ 12 179]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       307\n",
      "           1       1.00      0.94      0.97       191\n",
      "\n",
      "    accuracy                           0.98       498\n",
      "   macro avg       0.98      0.97      0.97       498\n",
      "weighted avg       0.98      0.98      0.98       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "# compute the accuracy score\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# compute the classification report\n",
    "cr = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# print the results\n",
    "print(f'Training accuracy: {accuracy}')\n",
    "print(f'Confusion matrix:\\n{cm}')\n",
    "print(f'Classification report:\\n{cr}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "True positive rate: 0.94\n",
      "False positive rate: 0.00\n",
      "True negative rate: 1.00\n",
      "False negative rate: 0.06\n",
      "Precision: 1.00\n",
      "Recall: 0.94\n",
      "F1-score: 0.97\n",
      "Support: 191\n"
     ]
    }
   ],
   "source": [
    "# Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "# compute the predictions on the training data\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "# compute the accuracy score\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# compute the true positive rate, false positive rate, true negative rate, and false negative rate\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "tnr = tn / (tn + fp)\n",
    "fnr = fn / (fn + tp)\n",
    "\n",
    "# compute the precision, recall, and f1-score\n",
    "cr = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "precision = cr['1']['precision']\n",
    "recall = cr['1']['recall']\n",
    "f1 = cr['1']['f1-score']\n",
    "support = cr['1']['support']\n",
    "\n",
    "# print the results\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'True positive rate: {tpr:.2f}')\n",
    "print(f'False positive rate: {fpr:.2f}')\n",
    "print(f'True negative rate: {tnr:.2f}')\n",
    "print(f'False negative rate: {fnr:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-score: {f1:.2f}')\n",
    "print(f'Support: {support}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (rf2): 0.8614457831325302\n"
     ]
    }
   ],
   "source": [
    "# Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "# create the classifier\n",
    "rf2 = RandomForestClassifier(random_state=123, min_samples_leaf=5, max_depth=5)\n",
    "\n",
    "# fit the classifier to the training data\n",
    "rf2.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the training data\n",
    "y_train_pred2 = rf2.predict(X_train)\n",
    "\n",
    "# compute the accuracy score\n",
    "accuracy2 = accuracy_score(y_train, y_train_pred2)\n",
    "\n",
    "# print the accuracy score\n",
    "print(f'Training accuracy (rf2): {accuracy2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (rf2): 0.86\n",
      "True positive rate (rf2): 0.73\n",
      "False positive rate (rf2): 0.06\n",
      "True negative rate (rf2): 0.94\n",
      "False negative rate (rf2): 0.27\n",
      "Precision (rf2): 0.89\n",
      "Recall (rf2): 0.73\n",
      "F1-score (rf2): 0.80\n",
      "Support (rf2): 191\n"
     ]
    }
   ],
   "source": [
    "# What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "# compute the predictions on the training data\n",
    "y_train_pred2 = rf2.predict(X_train)\n",
    "\n",
    "# compute the accuracy score\n",
    "accuracy2 = accuracy_score(y_train, y_train_pred2)\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm2 = confusion_matrix(y_train, y_train_pred2)\n",
    "\n",
    "# compute the true positive rate, false positive rate, true negative rate, and false negative rate\n",
    "tn2, fp2, fn2, tp2 = cm2.ravel()\n",
    "tpr2 = tp2 / (tp2 + fn2)\n",
    "fpr2 = fp2 / (fp2 + tn2)\n",
    "tnr2 = tn2 / (tn2 + fp2)\n",
    "fnr2 = fn2 / (fn2 + tp2)\n",
    "\n",
    "# compute the precision, recall, and f1-score\n",
    "cr2 = classification_report(y_train, y_train_pred2, output_dict=True)\n",
    "precision2 = cr2['1']['precision']\n",
    "recall2 = cr2['1']['recall']\n",
    "f1_2 = cr2['1']['f1-score']\n",
    "support2 = cr2['1']['support']\n",
    "\n",
    "# print the results\n",
    "print(f'Accuracy (rf2): {accuracy2:.2f}')\n",
    "print(f'True positive rate (rf2): {tpr2:.2f}')\n",
    "print(f'False positive rate (rf2): {fpr2:.2f}')\n",
    "print(f'True negative rate (rf2): {tnr2:.2f}')\n",
    "print(f'False negative rate (rf2): {fnr2:.2f}')\n",
    "print(f'Precision (rf2): {precision2:.2f}')\n",
    "print(f'Recall (rf2): {recall2:.2f}')\n",
    "print(f'F1-score (rf2): {f1_2:.2f}')\n",
    "print(f'Support (rf2): {support2}')\n",
    "\n",
    "\n",
    "# The output of this code should show that the training accuracy, precision, recall, and f1-score of `rf2` are all lower than those of `rf`,\n",
    "# while the false positive rate and false negative rate are higher. The support value is the same since it is based on the number of instances\n",
    "# of the positive class in the training data.\n",
    "\n",
    "# The reason why `rf2` has lower performance on the in-sample data is that the increased `min_samples_leaf` and decreased `max_depth`\n",
    "# values have made the model less complex and less flexible, which can lead to underfitting. Underfitting occurs when the model is\n",
    "# too simple to capture the complexity of the training data, resulting in poor performance on both the training and test data. In this case,\n",
    "# `rf2` is likely underfitting the training data, leading to lower accuracy and other metrics.\n",
    "\n",
    "# It's important to note that the evaluation metrics on the training data are not necessarily indicative of the performance of the models on new,\n",
    "# unseen data. It's important to evaluate the models on a separate validation or testing dataset to get a better sense of their generalization\n",
    "# performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf train accuracy: 0.9759\n",
      "rf validate accuracy: 0.7991\n",
      "rf2 train accuracy: 0.8614\n",
      "rf2 validate accuracy: 0.8178\n"
     ]
    }
   ],
   "source": [
    "# After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "# create a list of tuples containing the name and model object for each model\n",
    "# Based on the output, it looks like the first model (rf) has the best performance on both the train and validate data sets,\n",
    "# with a training accuracy of 0.9759 and similar metrics on the validation set. The second model (rf2) has a lower training accuracy of 0.8614.\n",
    "\n",
    "# create a list of tuples containing the name and model object for each model\n",
    "models = [\n",
    "    ('rf', rf),\n",
    "    ('rf2', rf2)\n",
    "]\n",
    "\n",
    "# evaluate each model on the train and validate data sets\n",
    "for name, model in models:\n",
    "    # make predictions on the train data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    # make predictions on the validate data\n",
    "    y_validate_pred = model.predict(X_validate)\n",
    "    \n",
    "    # compute the accuracy score for train and validate data sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    validate_accuracy = accuracy_score(y_validate, y_validate_pred)\n",
    "    \n",
    "    # print the accuracy scores for train and validate data sets\n",
    "    print(f'{name} train accuracy: {train_accuracy:.4f}')\n",
    "    print(f'{name} validate accuracy: {validate_accuracy:.4f}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
