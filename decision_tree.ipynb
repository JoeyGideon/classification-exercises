{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the titanic data, in your classification-exercises repository, create a notebook, decision_tree.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from acquire import get_titanic_data\n",
    "\n",
    "# Load Titanic data into a pandas DataFrame\n",
    "df_titanic = get_titanic_data()\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.6161616161616161\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is \n",
    "# predicting the most prevelant class in the training dataset (the mode). When you make those predictions, \n",
    "# what is your accuracy? This is your baseline accuracy.\n",
    "# Count the number of passengers who did not survive\n",
    "num_not_survived = df_titanic['survived'].value_counts()[0]\n",
    "\n",
    "# Calculate the total number of passengers\n",
    "total_passengers = len(df_titanic)\n",
    "\n",
    "# Calculate the baseline accuracy\n",
    "baseline_accuracy = num_not_survived / total_passengers\n",
    "\n",
    "print(\"Baseline accuracy:\", baseline_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing sample: 0.7597765363128491\n"
     ]
    }
   ],
   "source": [
    "# Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "\n",
    "# Load the titanic dataset\n",
    "df_titanic = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Select the features and target variable\n",
    "X = df_titanic.drop(columns=['survived'])\n",
    "y = df_titanic['survived']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier to the training sample\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing sample\n",
    "y_pred_test = dt.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier on the testing sample\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Accuracy on testing sample:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training sample: 1.0\n",
      "Accuracy on testing sample: 0.7597765363128491\n",
      "Confusion matrix on testing sample:\n",
      " [[82 23]\n",
      " [20 54]]\n",
      "Classification report on testing sample:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79       105\n",
      "           1       0.70      0.73      0.72        74\n",
      "\n",
      "    accuracy                           0.76       179\n",
      "   macro avg       0.75      0.76      0.75       179\n",
      "weighted avg       0.76      0.76      0.76       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the titanic dataset\n",
    "df_titanic = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Select the features and target variable\n",
    "X = df_titanic.drop(columns=['survived'])\n",
    "y = df_titanic['survived']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier to the training sample\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training and testing samples\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier on the training and testing samples\n",
    "accuracy_train = dt.score(X_train, y_train)\n",
    "accuracy_test = dt.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training sample:\", accuracy_train)\n",
    "print(\"Accuracy on testing sample:\", accuracy_test)\n",
    "\n",
    "# Evaluate the confusion matrix and classification report on the testing sample\n",
    "print(\"Confusion matrix on testing sample:\\n\", confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification report on testing sample:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "# The `score` method returns the mean accuracy on the given data and labels, while the `confusion_matrix` function computes the confusion matrix to evaluate the accuracy of a classification. The `classification_report` function computes several classification metrics, including precision, recall, f1-score, and support, for each class.\n",
    "\n",
    "# The results show that the model achieves perfect accuracy on the training sample, but only 78.8% accuracy on the testing sample,\n",
    "# which indicates some overfitting to the training data. The confusion matrix and classification report show that the model performs \n",
    "# reasonably well on both classes, but has a slightly higher precision and recall for the negative class (did not survive) compared \n",
    "# to the positive class (survive Overall, the model can benefit from some parameter tuning to improve its performance on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7597765363128491\n",
      "True positive rate (TPR): 0.7297297297297297\n",
      "False positive rate (FPR): 0.21904761904761905\n",
      "True negative rate (TNR): 0.780952380952381\n",
      "False negative rate (FNR): 0.2702702702702703\n",
      "Precision: 0.7012987012987013\n",
      "Recall: 0.7297297297297297\n",
      "F1-score: 0.7152317880794701\n",
      "Support: [105  74]\n"
     ]
    }
   ],
   "source": [
    "# Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the titanic dataset\n",
    "df_titanic = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Select the features and target variable\n",
    "X = df_titanic.drop(columns=['survived'])\n",
    "y = df_titanic['survived']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier to the training sample\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing sample\n",
    "y_pred_test = dt.predict(X_test)\n",
    "\n",
    "# Compute the accuracy, confusion matrix, and classification report on the testing sample\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "tnr = tn / (tn + fp)\n",
    "fnr = fn / (fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tpr\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "support = np.bincount(y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"True positive rate (TPR):\", tpr)\n",
    "print(\"False positive rate (FPR):\", fpr)\n",
    "print(\"True negative rate (TNR):\", tnr)\n",
    "print(\"False negative rate (FNR):\", fnr)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1_score)\n",
    "print(\"Support:\", support)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7988826815642458\n",
      "True positive rate (TPR): 0.6891891891891891\n",
      "False positive rate (FPR): 0.12380952380952381\n",
      "True negative rate (TNR): 0.8761904761904762\n",
      "False negative rate (FNR): 0.3108108108108108\n",
      "Precision: 0.796875\n",
      "Recall: 0.6891891891891891\n",
      "F1-score: 0.7391304347826088\n",
      "Support: [105  74]\n"
     ]
    }
   ],
   "source": [
    "# Run through steps 2-4 using a different max_depth value.\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the titanic dataset\n",
    "df_titanic = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Select the features and target variable\n",
    "X = df_titanic.drop(columns=['survived'])\n",
    "y = df_titanic['survived']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "# Initialize the decision tree classifier with max_depth=3\n",
    "dt_depth3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training sample\n",
    "dt_depth3.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing sample\n",
    "y_pred_test = dt_depth3.predict(X_test)\n",
    "\n",
    "# Compute the accuracy, confusion matrix, and classification report on the testing sample\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "tnr = tn / (tn + fp)\n",
    "fnr = fn / (fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tpr\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "support = np.bincount(y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"True positive rate (TPR):\", tpr)\n",
    "print(\"False positive rate (FPR):\", fpr)\n",
    "print(\"True negative rate (TNR):\", tnr)\n",
    "print(\"False negative rate (FNR):\", fnr)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1_score)\n",
    "print(\"Support:\", support)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of default model on training sample: 1.0\n",
      "Accuracy of model with max_depth=3 on training sample: 0.8342696629213483\n"
     ]
    }
   ],
   "source": [
    "# Which model performs better on your in-sample data?\n",
    "# Compute the accuracy of the default model on the training sample\n",
    "y_pred_train_default = dt.predict(X_train)\n",
    "accuracy_default = accuracy_score(y_train, y_pred_train_default)\n",
    "\n",
    "# Compute the accuracy of the model with max_depth=3 on the training sample\n",
    "y_pred_train_depth3 = dt_depth3.predict(X_train)\n",
    "accuracy_depth3 = accuracy_score(y_train, y_pred_train_depth3)\n",
    "\n",
    "print(\"Accuracy of default model on training sample:\", accuracy_default)\n",
    "print(\"Accuracy of model with max_depth=3 on training sample:\", accuracy_depth3)\n",
    "\n",
    "\n",
    "# If the output shows that both the default model and the model with `max_depth=3` have the same accuracy of 83.4% on the training sample, \n",
    "# it suggests that the model with `max_depth=3` is not overfitting to the training data as much as the default model. \n",
    "# This may be due to the fact that the `max_depth` hyperparameter is limiting the complexity of the model and preventing it \n",
    "# from memorizing the training data too well.\n",
    "\n",
    "# In this case, we may prefer the model with `max_depth=3` over the default model because it is likely to generalize better to new,\n",
    "#  unseen data. However, we should still evaluate the models on the testing sample to confirm their performance and choose the one with\n",
    "#  the best overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (498, 14), Validate: (214, 14), Test: (179, 14)\n"
     ]
    }
   ],
   "source": [
    "def split_data(df, target):\n",
    "    '''\n",
    "    take in a DataFrame and return train, validate, and test DataFrames; stratify on target variable.\n",
    "    return train, validate, test DataFrames.\n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123, stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, \n",
    "                                       test_size=.3, \n",
    "                                       random_state=123, \n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test\n",
    "import pandas as pd\n",
    "from acquire import get_titanic_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = 'survived'\n",
    "train_titanic, validate_titanic, test_titanic = split_data(df_titanic, target)\n",
    "\n",
    "# Print the three datasets\n",
    "\n",
    "print(f'Train: {train_titanic.shape}, Validate: {validate_titanic.shape}, Test: {test_titanic.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which model performs best on your out-of-sample data, the validate set?\n",
    "\n",
    "Based on the test set accuracies, the model with `max_depth=3` performs better on the out-of-sample data than the default model. The accuracy of the model with `max_depth=3` is 0.7989 while the accuracy of the default model is 0.7598. Therefore, the model with `max_depth=3` is likely the better choice for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>phone_service</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>online_security</th>\n",
       "      <th>online_backup</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>churn</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>internet_service_type</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>65.6</td>\n",
       "      <td>593.3</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Mailed check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>59.9</td>\n",
       "      <td>542.4</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Mailed check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>73.9</td>\n",
       "      <td>280.85</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Electronic check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Electronic check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>83.9</td>\n",
       "      <td>267.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Mailed check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  senior_citizen partner dependents  tenure phone_service  \\\n",
       "0  Female               0     Yes        Yes       9           Yes   \n",
       "1    Male               0      No         No       9           Yes   \n",
       "2    Male               0      No         No       4           Yes   \n",
       "3    Male               1     Yes         No      13           Yes   \n",
       "4  Female               1     Yes         No       3           Yes   \n",
       "\n",
       "  multiple_lines online_security online_backup device_protection tech_support  \\\n",
       "0             No              No           Yes                No          Yes   \n",
       "1            Yes              No            No                No           No   \n",
       "2             No              No            No               Yes           No   \n",
       "3             No              No           Yes               Yes           No   \n",
       "4             No              No            No                No          Yes   \n",
       "\n",
       "  streaming_tv streaming_movies paperless_billing  monthly_charges  \\\n",
       "0          Yes               No               Yes             65.6   \n",
       "1           No              Yes                No             59.9   \n",
       "2           No               No               Yes             73.9   \n",
       "3          Yes              Yes               Yes             98.0   \n",
       "4          Yes               No               Yes             83.9   \n",
       "\n",
       "  total_charges churn   contract_type internet_service_type      payment_type  \n",
       "0         593.3    No        One year                   DSL      Mailed check  \n",
       "1         542.4    No  Month-to-month                   DSL      Mailed check  \n",
       "2        280.85   Yes  Month-to-month           Fiber optic  Electronic check  \n",
       "3       1237.85   Yes  Month-to-month           Fiber optic  Electronic check  \n",
       "4         267.4   Yes  Month-to-month           Fiber optic      Mailed check  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Work through these same exercises using the Telco dataset.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from acquire import get_telco_data\n",
    "\n",
    "# Load Telco data into a pandas DataFrame\n",
    "df_telco = get_telco_data()\n",
    "df_telco = df_telco.drop(['payment_type_id', 'internet_service_type_id', 'contract_type_id', 'customer_id'], axis=1)\n",
    "df_telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Prediction: No\n",
      "Baseline Accuracy: 0.7346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Determine the most prevalent class in the 'churn' column\n",
    "mode = df_telco['churn'].mode()[0]\n",
    "\n",
    "# Make all predictions using the most prevalent class\n",
    "baseline_preds = np.full(df_telco.shape[0], mode)\n",
    "\n",
    "# Calculate the accuracy of the baseline model\n",
    "baseline_accuracy = (baseline_preds == df_telco['churn']).mean()\n",
    "\n",
    "print(f\"Baseline Prediction: {mode}\")\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training sample: 0.9978700745473909\n",
      "Accuracy on testing sample: 0.758694109297374\n",
      "Confusion matrix on testing sample:\n",
      " [[893 143]\n",
      " [197 176]]\n",
      "Classification report on testing sample:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.86      0.84      1036\n",
      "         Yes       0.55      0.47      0.51       373\n",
      "\n",
      "    accuracy                           0.76      1409\n",
      "   macro avg       0.69      0.67      0.67      1409\n",
      "weighted avg       0.75      0.76      0.75      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Select the features and target variable\n",
    "X = df_telco.drop(columns=['churn'])\n",
    "y = df_telco['churn']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier to the training sample\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training and testing samples\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier on the training and testing samples\n",
    "accuracy_train = dt.score(X_train, y_train)\n",
    "accuracy_test = dt.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training sample:\", accuracy_train)\n",
    "print(\"Accuracy on testing sample:\", accuracy_test)\n",
    "\n",
    "# Evaluate the confusion matrix and classification report on the testing sample\n",
    "print(\"Confusion matrix on testing sample:\\n\", confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification report on testing sample:\\n\", classification_report(y_test, y_pred_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation sample: 0.7693399574166075\n",
      "True positive rate (TPR): 0.48320413436692505\n",
      "False positive rate (FPR): 0.1223091976516634\n",
      "True negative rate (TNR): 0.8776908023483366\n",
      "False negative rate (FNR): 0.5167958656330749\n",
      "Precision: 0.5993589743589743\n",
      "Recall: 0.48320413436692505\n",
      "F1-score: 0.5350500715307582\n",
      "Support: [1022  387]\n",
      "Accuracy on testing sample: 0.7544357700496807\n",
      "True positive rate (TPR): 0.47989276139410186\n",
      "False positive rate (FPR): 0.14671814671814673\n",
      "True negative rate (TNR): 0.8532818532818532\n",
      "False negative rate (FNR): 0.5201072386058981\n",
      "Precision: 0.540785498489426\n",
      "Recall: 0.47989276139410186\n",
      "F1-score: 0.5085227272727274\n",
      "Support: [1036  373]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Convert target variable to numeric values\n",
    "df_telco['churn'] = pd.factorize(df_telco['churn'])[0]\n",
    "\n",
    "# Select the features and target variable\n",
    "X = df_telco.drop(columns=['churn'])\n",
    "y = df_telco['churn']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training, validation, and testing subsets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Impute missing values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_val = imp.transform(X_val)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier to the training sample\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation sample\n",
    "y_pred_val = dt.predict(X_val)\n",
    "\n",
    "# Compute the accuracy, confusion matrix, and classification report on the validation sample\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "tnr = tn / (tn + fp)\n",
    "fnr = fn / (fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tpr\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "support = np.bincount(y_val)\n",
    "\n",
    "print(\"Accuracy on validation sample:\", accuracy)\n",
    "print(\"True positive rate (TPR):\", tpr)\n",
    "print(\"False positive rate (FPR):\", fpr)\n",
    "print(\"True negative rate (TNR):\", tnr)\n",
    "print(\"False negative rate (FNR):\", fnr)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1_score)\n",
    "print(\"Support:\", support)\n",
    "\n",
    "# Make predictions on the testing sample\n",
    "y_pred_test = dt.predict(X_test)\n",
    "\n",
    "# Compute the accuracy, confusion matrix, and classification report on the testing sample\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "tnr = tn / (tn + fp)\n",
    "fnr = fn / (fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tpr\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "support = np.bincount(y_test)\n",
    "\n",
    "print(\"Accuracy on testing sample:\", accuracy)\n",
    "print(\"True positive rate (TPR):\", tpr)\n",
    "print(\"False positive rate (FPR):\", fpr)\n",
    "print(\"True negative rate (TNR):\", tnr)\n",
    "print(\"False negative rate (FNR):\", fnr)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1_score)\n",
    "print(\"Support:\", support)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7835344215755855\n",
      "True positive rate (TPR): 0.3351206434316354\n",
      "False positive rate (FPR): 0.05501930501930502\n",
      "True negative rate (TNR): 0.944980694980695\n",
      "False negative rate (FNR): 0.6648793565683646\n",
      "Precision: 0.6868131868131868\n",
      "Recall: 0.3351206434316354\n",
      "F1-score: 0.45045045045045046\n",
      "Support: [1036  373]\n"
     ]
    }
   ],
   "source": [
    "# Run through steps 2-4 using a different max_depth value.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Convert target variable to numeric values\n",
    "df_telco['churn'] = pd.factorize(df_telco['churn'])[0]\n",
    "\n",
    "# Select the features and target variable\n",
    "X = df_telco.drop(columns=['churn'])\n",
    "y = df_telco['churn']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "# Initialize the decision tree classifier with max_depth=3\n",
    "dt_depth3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training sample\n",
    "dt_depth3.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing sample\n",
    "y_pred_test = dt_depth3.predict(X_test)\n",
    "\n",
    "# Compute the accuracy, confusion matrix, and classification report on the testing sample\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "tnr = tn / (tn + fp)\n",
    "fnr = fn / (fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tpr\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "support = np.bincount(y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"True positive rate (TPR):\", tpr)\n",
    "print(\"False positive rate (FPR):\", fpr)\n",
    "print(\"True negative rate (TNR):\", tnr)\n",
    "print(\"False negative rate (FNR):\", fnr)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1_score)\n",
    "print(\"Support:\", support)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of default model on training sample: 1.0\n",
      "Accuracy of model with max_depth=3 on training sample: 0.7911401391452506\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Impute missing values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X = imp.fit_transform(X)\n",
    "\n",
    "# Initialize the decision tree classifier with default parameters\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "dt.fit(X, y)\n",
    "\n",
    "# Initialize the decision tree classifier with max_depth=3\n",
    "dt_depth3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "dt_depth3.fit(X, y)\n",
    "\n",
    "# Make predictions on the training sample\n",
    "y_pred_train_default = dt.predict(X)\n",
    "accuracy_default = accuracy_score(y, y_pred_train_default)\n",
    "\n",
    "# Compute the accuracy of the model with max_depth=3 on the training sample\n",
    "y_pred_train_depth3 = dt_depth3.predict(X)\n",
    "accuracy_depth3 = accuracy_score(y, y_pred_train_depth3)\n",
    "\n",
    "print(\"Accuracy of default model on training sample:\", accuracy_default)\n",
    "print(\"Accuracy of model with max_depth=3 on training sample:\", accuracy_depth3)\n",
    "\n",
    "#model with the max depth of 3 is the better model so it is not overfitting.\n",
    "# this model performs the best with all the data samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with this model on other datasets with a higher number of output classes.(Bonus per Misty)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
